# Flood Cascade System - Python Backend

Real-time rainfall data processing and API server for the Flood Cascade System dashboard.

## Features

- **Real-time Data Processing**: Processes CSV rainfall datasets
- **Risk Analysis API**: Calculates flood risk zones and anomalies
- **REST Endpoints**: Multiple endpoints for dashboard integration
- **CORS Enabled**: Cross-origin support for frontend communication
- **Auto-refresh**: Watches for data updates

## Setup & Installation

### Prerequisites

- Python 3.9 or higher
- pip (Python package manager)

### Installation

1. **Install Dependencies**

   ```bash
   pip install -r requirements.txt
   ```

2. **Verify Installation**
   ```bash
   python -c "import flask; print('Flask version:', flask.__version__)"
   ```

### Running the Backend

#### Option 1: Using the Startup Script (Windows)

```bash
cd backend
start.bat
```

#### Option 2: Manual Start

```bash
cd backend
python app.py
```

The server will start at `http://localhost:5000`

## API Endpoints

### Health Check

- **GET** `/api/health`
  - Returns: Server status and timestamp

### Rainfall Data

- **GET** `/api/rainfall-data`
  - Returns: All processed rainfall data (critical zones, risk analysis, impact data)
  - Use this for dashboard integration

### Risk Zones

- **GET** `/api/risk-zones`
  - Returns: Current critical flood risk zones

### Risk Analysis

- **GET** `/api/risk-analysis`
  - Returns: Detailed risk analysis with rainfall anomalies

### Impact Data

- **GET** `/api/impact-data`
  - Returns: Infrastructure and sector impact metrics

### Alerts

- **GET** `/api/alerts`
  - Returns: Active government alerts based on risk zones

### Statistics

- **GET** `/api/statistics`
  - Returns: System statistics (records count, data source, etc.)

### Search

- **POST** `/api/search`
  - Request body: `{ "riskLevel": "Critical", "subdivision": "TAMIL NADU" }`
  - Returns: Filtered risk analysis results

### District Data

- **GET** `/api/district/<district_name>`
  - Returns: Normal rainfall data for specific district

### Refresh Data

- **POST** `/api/refresh`
  - Manually refresh data from CSV files

## Data Files

The backend expects CSV files in `../src/data/`:

1. **rainfall in india 1901-2015.csv**
   - Historical rainfall data (1901-2015)
   - Fields: YEAR, SUBDIVISION, ANNUAL, JAN-DEC

2. **district wise rainfall normal.csv**
   - District-level rainfall normals
   - Fields: DISTRICT, ANNUAL, JAN-DEC

3. **processedData.json**
   - Auto-generated by data processor
   - Contains: Risk zones, impact data, anomaly analysis

## Integration with Frontend

The React frontend fetches data via the custom hook:

```javascript
import { useRainfallData } from "./hooks/useRainfallData";

const { criticalZones, riskAnalysis, alerts, loading, error } =
  useRainfallData();
```

### Data Refresh Intervals

- **Rainfall Data**: Every 30 seconds
- **Alerts**: Every 15 seconds
- **Backend Health**: Every 10 seconds

## Troubleshooting

### Port Already in Use

```bash
# Find process on port 5000
netstat -ano | findstr :5000

# Kill the process (replace PID)
taskkill /PID <PID> /F
```

### Module Not Found

```bash
# Ensure requirements are installed
pip install --upgrade -r requirements.txt
```

### CORS Issues

Backend has CORS enabled for all origins. If issues persist:

- Check Firefox/Chrome console for CORS headers
- Verify backend is running on `localhost:5000`

### Data Not Updating

- Check that CSV files exist in `../src/data/`
- Ensure permissions allow file reading
- Check backend console for error messages

## Performance Notes

- First load processes ~4100 historical records + 641 district normals
- Risk analysis runs on-demand
- Data is cached after first load
- Full refresh takes ~500-1000ms

## File Structure

```
backend/
├── app.py              # Main Flask application
├── requirements.txt    # Python dependencies
├── .env               # Environment configuration
├── start.bat          # Windows startup script
└── README.md          # This file
```

## Environment Variables

Edit `.env` to configure:

```
FLASK_ENV=development      # or production
FLASK_DEBUG=True          # Enable debug mode
PORT=5000                 # Server port
HOST=0.0.0.0             # Bind to all interfaces
```

## Support

For issues or questions:

1. Check the console output for error messages
2. Verify CSV files are in correct location
3. Ensure port 5000 is not blocked by firewall
4. Check backend and frontend are communicating (see Network tab in DevTools)
